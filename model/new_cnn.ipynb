{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrjoe\\OneDrive\\Desktop\\New folder\\sweng25_group11-microsoftspamdetection\\sklearn-env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14400/14400 - 345s - 24ms/step - accuracy: 0.7861 - loss: 0.4964 - val_accuracy: 0.8097 - val_loss: 0.4409\n",
      "Epoch 2/10\n",
      "14400/14400 - 357s - 25ms/step - accuracy: 0.8173 - loss: 0.4486 - val_accuracy: 0.8164 - val_loss: 0.4542\n",
      "Epoch 3/10\n",
      "14400/14400 - 352s - 24ms/step - accuracy: 0.8321 - loss: 0.4241 - val_accuracy: 0.8068 - val_loss: 0.4748\n",
      "Epoch 4/10\n",
      "14400/14400 - 341s - 24ms/step - accuracy: 0.8439 - loss: 0.4036 - val_accuracy: 0.8383 - val_loss: 0.4095\n",
      "Epoch 5/10\n",
      "14400/14400 - 336s - 23ms/step - accuracy: 0.8516 - loss: 0.3846 - val_accuracy: 0.8029 - val_loss: 0.4735\n",
      "Epoch 6/10\n",
      "14400/14400 - 336s - 23ms/step - accuracy: 0.8600 - loss: 0.3683 - val_accuracy: 0.8184 - val_loss: 0.4399\n",
      "Epoch 7/10\n",
      "14400/14400 - 336s - 23ms/step - accuracy: 0.8651 - loss: 0.3528 - val_accuracy: 0.8119 - val_loss: 0.4675\n",
      "\u001b[1m4500/4500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CNN (Tokenized + Embedding) Results:\n",
      "Accuracy: 0.8636\n",
      "Precision: 0.6000\n",
      "Recall: 0.5694\n",
      "F1 Score: 0.5843\n",
      "CNN model saved as 'cnn_model_precision.h5'\n",
      "Tokenizer and threshold saved as 'cnn_model_info_precision.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load CSV and preprocess text\n",
    "df = pd.read_csv(\"data/raw_data.csv\", header=None)\n",
    "df.columns = ['message', 'label']\n",
    "\n",
    "from backend.TextPreprocessingUtils import preprocess_text\n",
    "df['processed_message'] = df['message'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize and pad\n",
    "vocab_size = 10000\n",
    "maxlen = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['processed_message'])\n",
    "sequences = tokenizer.texts_to_sequences(df['processed_message'])\n",
    "padded = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded, df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Compute class weights to handle imbalance\n",
    "cw = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(cw))\n",
    "\n",
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128, input_length=maxlen),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Predict with threshold tuning\n",
    "y_probs = model.predict(X_test)\n",
    "threshold = 0.6  \n",
    "y_pred = (y_probs > threshold).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\" CNN (Tokenized + Embedding) Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the Keras model (HDF5 format)\n",
    "model.save(\"../model/cnn_model_precision.h5\")\n",
    "\n",
    "# Save the tokenizer and threshold as a .pkl file\n",
    "model_info = {\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"threshold\": threshold\n",
    "}\n",
    "joblib.dump(model_info, \"../model/cnn_model_info:precision.pkl\")\n",
    "\n",
    "print(\"CNN model saved as 'cnn_model_precision.h5'\")\n",
    "print(\"Tokenizer and threshold saved as 'cnn_model_info_precision.pkl'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Accuracy: 0.6824\n",
      "Precision: 0.3109\n",
      "Recall: 0.7291\n",
      "F1 Score: 0.4359\n",
      "\n",
      "CNN:\n",
      "Accuracy: 0.6922\n",
      "Precision: 0.3183\n",
      "Recall: 0.7250\n",
      "F1 Score: 0.4423\n",
      "\n",
      "NB:\n",
      "Accuracy: 0.8359\n",
      "Precision: 0.6892\n",
      "Recall: 0.0458\n",
      "F1 Score: 0.0859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "svm_accuracy = accuracy_score(ytest, y_pred_svm)\n",
    "svm_precision = precision_score(ytest, y_pred_svm)\n",
    "svm_recall = recall_score(ytest, y_pred_svm)\n",
    "svm_f1 = f1_score(ytest, y_pred_svm)\n",
    "\n",
    "cnn_accuracy = accuracy_score(ytest, y_pred_cnn_labels)\n",
    "cnn_precision = precision_score(ytest, y_pred_cnn_labels)\n",
    "cnn_recall = recall_score(ytest, y_pred_cnn_labels)\n",
    "cnn_f1 = f1_score(ytest, y_pred_cnn_labels)\n",
    "\n",
    "nb_accuracy = accuracy_score(ytest, y_pred_nb)\n",
    "nb_precision = precision_score(ytest, y_pred_nb)\n",
    "nb_recall = recall_score(ytest, y_pred_nb)\n",
    "nb_f1 = f1_score(ytest, y_pred_nb)\n",
    "\n",
    "# Display Results\n",
    "print(\"SVM:\")\n",
    "print(f\"Accuracy: {svm_accuracy:.4f}\")\n",
    "print(f\"Precision: {svm_precision:.4f}\")\n",
    "print(f\"Recall: {svm_recall:.4f}\")\n",
    "print(f\"F1 Score: {svm_f1:.4f}\")\n",
    "print(\"\")\n",
    "print(\"CNN:\")\n",
    "print(f\"Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(f\"Precision: {cnn_precision:.4f}\")\n",
    "print(f\"Recall: {cnn_recall:.4f}\")\n",
    "print(f\"F1 Score: {cnn_f1:.4f}\")\n",
    "print(\"\")\n",
    "print(\"NB:\")\n",
    "print(f\"Accuracy: {nb_accuracy:.4f}\")\n",
    "print(f\"Precision: {nb_precision:.4f}\")\n",
    "print(f\"Recall: {nb_recall:.4f}\")\n",
    "print(f\"F1 Score: {nb_f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4500/4500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step\n",
      "Threshold sweep:\n",
      "Threshold: 0.30 | Precision: 0.2781 | Recall: 0.9275 | F1: 0.4279\n",
      "Threshold: 0.35 | Precision: 0.3131 | Recall: 0.8842 | F1: 0.4624\n",
      "Threshold: 0.40 | Precision: 0.3646 | Recall: 0.8256 | F1: 0.5059\n",
      "Threshold: 0.45 | Precision: 0.4399 | Recall: 0.7462 | F1: 0.5535\n",
      "Threshold: 0.50 | Precision: 0.4942 | Recall: 0.6848 | F1: 0.5741\n",
      "Threshold: 0.55 | Precision: 0.5425 | Recall: 0.6350 | F1: 0.5851\n",
      "Threshold: 0.60 | Precision: 0.5861 | Recall: 0.5884 | F1: 0.5873\n",
      "Threshold: 0.65 | Precision: 0.6318 | Recall: 0.5427 | F1: 0.5839\n",
      "Threshold: 0.70 | Precision: 0.6781 | Recall: 0.4950 | F1: 0.5723\n",
      "Threshold: 0.75 | Precision: 0.7271 | Recall: 0.4496 | F1: 0.5557\n",
      "Threshold: 0.80 | Precision: 0.7759 | Recall: 0.4029 | F1: 0.5304\n",
      "Threshold: 0.85 | Precision: 0.8271 | Recall: 0.3479 | F1: 0.4898\n",
      "Threshold: 0.90 | Precision: 0.8821 | Recall: 0.2842 | F1: 0.4299\n",
      "\n",
      "Top thresholds by precision:\n",
      "Threshold: 0.90 | Precision: 0.8821 | Recall: 0.2842 | F1: 0.4299\n",
      "Threshold: 0.85 | Precision: 0.8271 | Recall: 0.3479 | F1: 0.4898\n",
      "Threshold: 0.80 | Precision: 0.7759 | Recall: 0.4029 | F1: 0.5304\n",
      "Threshold: 0.75 | Precision: 0.7271 | Recall: 0.4496 | F1: 0.5557\n",
      "Threshold: 0.70 | Precision: 0.6781 | Recall: 0.4950 | F1: 0.5723\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict probabilities once\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Test multiple thresholds\n",
    "thresholds = np.arange(0.3, 0.91, 0.05)\n",
    "results = []\n",
    "\n",
    "print(\"Threshold sweep:\")\n",
    "for t in thresholds:\n",
    "    y_pred = (y_probs > t).astype(int)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results.append((t, precision, recall, f1))\n",
    "    print(f\"Threshold: {t:.2f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "# Sort by highest precision\n",
    "sorted_by_precision = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop thresholds by precision:\")\n",
    "for t, precision, recall, f1 in sorted_by_precision[:5]:\n",
    "    print(f\"Threshold: {t:.2f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a file\n",
    "model.save('cnn.keras')  # The file extension should be .keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
